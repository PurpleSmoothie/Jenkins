import json
import argparse
import os
import sys
import openai
from tenacity import retry, stop_after_attempt, wait_exponential


class LLMAnalyzer:
    def __init__(self):
        self.client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY", ""),
            base_url=os.getenv("LLM_BASE_URL", "https://api.openai.com/v1")
        )

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def analyze_query(self, query_data):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ LLM —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        prompt = self._build_prompt(query_data)

        try:
            response = self.client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=500
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ LLM: {str(e)}")
            return {
                "evaluation": "–æ—à–∏–±–∫–∞_–∞–Ω–∞–ª–∏–∑–∞",
                "severity": "HIGH",
                "recommendations": ["–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ LLM"]
            }

    def _build_prompt(self, query_data):
        explain_output = ' '.join(query_data.get('explain_output', [])) if query_data.get('explain_output') else 'N/A'
        tables = ', '.join(query_data.get('tables', [])) if query_data.get('tables') else 'N/A'
        
        return f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π SQL-–∑–∞–ø—Ä–æ—Å –∏ –µ–≥–æ EXPLAIN ANALYZE –≤—ã–≤–æ–¥ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:
1. –ò–¥–µ–∞–ª—å–Ω—ã–π (GOOD): 
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è < 50ms
   - –ù–µ—Ç seq_scan –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
   - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏

2. –ü—Ä–∏–µ–º–ª–µ–º—ã–π (ACCEPTABLE):
   - –†–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –µ—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
   - Seq scan –Ω–∞ —Ç–∞–±–ª–∏—Ü–∞—Ö < 10k —Å—Ç—Ä–æ–∫
   - –í–æ–∑–º–æ–∂–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Ä–æ—Å—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è < 200ms

3. –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è (NEEDS_IMPROVEMENT):
   - Seq scan –Ω–∞ –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
   - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è JOIN/WHERE
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è > 500ms
   - –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU

4. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π (CRITICAL):
   - DROP/DELETE –±–µ–∑ WHERE
   - –ü–æ–ª–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü > 1M —Å—Ç—Ä–æ–∫
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è > 2s
   - –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π

–ó–∞–ø—Ä–æ—Å: 
{query_data['query']}

EXPLAIN ANALYZE –≤—ã–≤–æ–¥:
{explain_output}

–¢–∞–±–ª–∏—Ü—ã: {tables}
–¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_data['type']}

–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Å—Ç—Ä–æ–≥–æ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "evaluation": "GOOD|ACCEPTABLE|NEEDS_IMPROVEMENT|CRITICAL",
  "severity": "LOW|MEDIUM|HIGH|CRITICAL",
  "execution_time": "–≤—Ä–µ–º—è_–≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
  "issues": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"],
  "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2"]
}}
"""


def generate_report(results):
    analyzer = LLMAnalyzer()
    report = []

    for item in results:
        if item.get('error'):
            analysis = {
                "evaluation": "CRITICAL",
                "severity": "CRITICAL",
                "issues": [f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {item['error']}"],
                "recommendations": ["–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å SQL"]
            }
        else:
            analysis = analyzer.analyze_query(item)

        report.append({
            "query": item["query"],
            "type": item["type"],
            "tables": item["tables"],
            "file_path": item["file_path"],
            "analysis": analysis
        })

    return report


def check_jenkins_criteria(report):
    critical_count = 0
    improvable_count = 0
    total = len(report)

    # –ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    if total == 0:
        print("‚ö†Ô∏è –ù–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
        return False

    for item in report:
        eval = item["analysis"]["evaluation"]
        if eval in ["CRITICAL"]:
            critical_count += 1
        if eval in ["NEEDS_IMPROVEMENT", "CRITICAL"]:
            improvable_count += 1

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
    print(f"- –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total}")
    print(f"- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {critical_count}")
    print(f"- –ó–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è: {improvable_count}/{total} ({improvable_count / total:.0%})")

    if critical_count > 0:
        print("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã! –ó–∞–ø—Ä–µ—â–∞—é –¥–µ–ø–ª–æ–π.")
        return False

    if improvable_count / total > 0.6:
        print("‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç—Ä–µ–±—É—é—Ç —É–ª—É—á—à–µ–Ω–∏—è (>60%). –ó–∞–ø—Ä–µ—â–∞—é –¥–µ–ø–ª–æ–π.")
        return False

    print("‚úÖ –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º. –†–∞–∑—Ä–µ—à–∞—é –¥–µ–ø–ª–æ–π.")
    return True


def main():
    parser = argparse.ArgumentParser(description='LLM Query Analyzer')
    parser.add_argument('--results', default='explain_results.json', help='Input EXPLAIN results')
    parser.add_argument('--report', default='llm_report.json', help='Output report file')
    args = parser.parse_args()

    with open(args.results, 'r', encoding='utf-8') as f:
        results = json.load(f)

    report = generate_report(results)

    with open(args.report, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    if not check_jenkins_criteria(report):
        sys.exit(1)

    sys.exit(0)


if __name__ == '__main__':
    main()