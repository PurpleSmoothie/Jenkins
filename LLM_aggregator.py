#!/usr/bin/env python3
"""
SQL Query Analyzer —á–µ—Ä–µ–∑ OpenRouter (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π API)
"""

import json
import argparse
import os
import sys
import logging
import re
from typing import Dict, List, Any

# –ò—Å–ø–æ–ª—å–∑—É–µ–º openai-–∫–ª–∏–µ–Ω—Ç (—Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenRouter)
import openai


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
logger = logging.getLogger(__name__)


class OpenRouterAnalyzer:
    def __init__(self):
        # –ü–æ–ª—É—á–∞–µ–º API-–∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            logger.error("‚ùå OPENROUTER_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
            raise ValueError("API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–Ω—ã –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        self.base_url = "https://openrouter.ai/api/v1"
        # üí° –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —É–º–Ω—É—é –º–æ–¥–µ–ª—å
        self.model = "qwen/qwen-72b-chat:free"  # –†–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ, —á–µ–º mistral

        try:
            self.client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            logger.info("‚úÖ OpenRouter –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenRouter: {e}")
            raise

    def _build_prompt(self, query_data: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç, —á—Ç–æ–±—ã LLM –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–ª issues –∏ recommendations"""
        explain_output = '\n'.join(query_data.get('explain_output', [])) if query_data.get('explain_output') else 'N/A'
        tables = ', '.join(query_data.get('tables', [])) if query_data.get('tables') else 'N/A'

        return f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π SQL-–∑–∞–ø—Ä–æ—Å –∏ –µ–≥–æ EXPLAIN ANALYZE –≤—ã–≤–æ–¥. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON.

–ó–∞–ø—Ä–æ—Å: 
{query_data['query']}

EXPLAIN ANALYZE:
{explain_output}

–¢–∞–±–ª–∏—Ü—ã: {tables}
–¢–∏–ø: {query_data['type']}

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:
- GOOD: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, –±—ã—Å—Ç—Ä–æ, —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏, –≤—Ä–µ–º—è < 50ms
- ACCEPTABLE: —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –µ—Å—Ç—å —Ä–∏—Å–∫–∏, –≤—Ä–µ–º—è < 200ms
- NEEDS_IMPROVEMENT: –º–µ–¥–ª–µ–Ω–Ω–æ, seq scan, –Ω–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤, –≤—Ä–µ–º—è > 500ms
- CRITICAL: DROP/DELETE –±–µ–∑ WHERE, –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ (>2s)

–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–ø–æ–ª–Ω–∏ –í–°–ï –ø–æ–ª—è:
- –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç ‚Äî –Ω–∞–ø–∏—à–∏ "No performance issues detected"
- –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç ‚Äî –Ω–∞–ø–∏—à–∏ "Query is well-optimized for current data size"
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø—É—Å—Ç—ã–µ –º–∞—Å—Å–∏–≤—ã
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π | –≤ evaluation ‚Äî —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ!

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
{{
  "evaluation": "GOOD",  // –û–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ!
  "severity": "LOW",
  "execution_time": "10ms",
  "issues": ["–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã 1", "–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã 2"],
  "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 2"]
}}
–ü—Ä–∏–º–µ—Ä 1:
–ó–∞–ø—Ä–æ—Å: SELECT * FROM users WHERE id = 1;
EXPLAIN: Index Scan using users_pkey on users ...
–û—Ç–≤–µ—Ç: {{
  "evaluation": "GOOD",
  "severity": "LOW",
  "execution_time": "0.1ms",
  "issues": ["No issues detected"],
  "recommendations": ["Query uses primary key index, optimal for lookups"]
}}

–ü—Ä–∏–º–µ—Ä 2:
–ó–∞–ø—Ä–æ—Å: SELECT * FROM logs;
EXPLAIN: Seq Scan on logs ...
–û—Ç–≤–µ—Ç: {{
  "evaluation": "NEEDS_IMPROVEMENT",
  "severity": "MEDIUM",
  "execution_time": "120ms",
  "issues": ["Full table scan on large table"],
  "recommendations": ["Create index on frequently queried columns"]
}}
"""

    def _extract_json(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–∞–¥—ë–∂–Ω–æ"""
        # –£–±–∏—Ä–∞–µ–º Markdown
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)

        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –ø–æ–ª–Ω—É—é JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—É
        stack = []
        start = -1
        for i, char in enumerate(text):
            if char == '{':
                if start == -1:
                    start = i
                stack.append(char)
            elif char == '}':
                if stack:
                    stack.pop()
                    if not stack:  # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞
                        try:
                            return json.loads(text[start:i+1])
                        except json.JSONDecodeError as e:
                            logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                            return None
        return None

    def _fix_evaluation(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è evaluation"""
        if "|" in str(result.get("evaluation", "")):
            result["evaluation"] = "ACCEPTABLE"
            result["issues"] = result.get("issues", []) + ["LLM –≤–µ—Ä–Ω—É–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –≤ evaluation"]
        return result

    def _ensure_non_empty_fields(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ issues –∏ recommendations –Ω–µ –ø—É—Å—Ç—ã–µ"""
        if not result.get("issues"):
            result["issues"] = ["No performance issues detected"]

        if not result.get("recommendations"):
            result["recommendations"] = [
                "Query is efficient for current data size",
                "Consider indexing if table grows beyond 10k rows"
            ]
        return result

    def analyze_query(self, query_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω SQL-–∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ LLM"""
        prompt = self._build_prompt(query_data)

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=500
            )
            content = response.choices[0].message.content.strip()
            logger.info(f"üìù LLM response for query: {query_data['query'][:50]}...")
            logger.debug(f"Raw LLM output: {content}")

            # –ü–æ–ø—ã—Ç–∫–∞ 1: –ø—Ä—è–º–æ–π JSON
            try:
                result = json.loads(content)
                if isinstance(result, dict):
                    result = self._fix_evaluation(result)
                    result = self._ensure_non_empty_fields(result)
                    return result
            except json.JSONDecodeError:
                pass

            # –ü–æ–ø—ã—Ç–∫–∞ 2: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞
            try:
                extracted = self._extract_json(content)
                if extracted:
                    extracted = self._fix_evaluation(extracted)
                    extracted = self._ensure_non_empty_fields(extracted)
                    return extracted
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ JSON: {e}")

            # –§–æ–ª–ª–±—ç–∫: —Ä—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM")
            return {
                "evaluation": "ACCEPTABLE",
                "severity": "MEDIUM",
                "execution_time": "unknown",
                "issues": ["–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM"],
                "recommendations": [
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–ø—Ä–æ—Å –≤—Ä—É—á–Ω—É—é",
                    "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã"
                ]
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenRouter: {e}")
            return {
                "evaluation": "ACCEPTABLE",
                "severity": "HIGH",
                "execution_time": "unknown",
                "issues": [f"–û—à–∏–±–∫–∞ API: {str(e)}"],
                "recommendations": ["–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API"]
            }


def generate_report(results_file: str, analyzer: OpenRouterAnalyzer) -> List[Dict]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –ø–æ –≤—Å–µ–º –∑–∞–ø—Ä–æ—Å–∞–º"""
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {results_file}: {e}")
        sys.exit(1)

    report = []
    for item in results:
        if item.get('error'):
            analysis = {
                "evaluation": "CRITICAL",
                "severity": "CRITICAL",
                "execution_time": "0ms",
                "issues": [f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {item['error']}"],
                "recommendations": ["–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å SQL"]
            }
        else:
            analysis = analyzer.analyze_query(item)

        report.append({
            "query": item["query"],
            "type": item["type"],
            "tables": item.get("tables", []),
            "file_path": item.get("file_path", "unknown"),
            "analysis": analysis
        })

    return report


def check_deployment_criteria(report: List[Dict]) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ —Ä–∞–∑—Ä–µ—à–∏—Ç—å –¥–µ–ø–ª–æ–π"""
    critical_count = 0
    improvable_count = 0
    total = len(report)

    if total == 0:
        print("‚ö†Ô∏è –ù–µ—Ç SQL-–∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
        return False

    for item in report:
        eval_status = item["analysis"]["evaluation"]
        if eval_status == "CRITICAL":
            critical_count += 1
        if eval_status in ["NEEDS_IMPROVEMENT", "CRITICAL"]:
            improvable_count += 1

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
    print(f"- –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total}")
    print(f"- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö: {critical_count}")
    print(f"- –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è: {improvable_count}/{total} ({improvable_count / total:.0%})")

    if critical_count > 0:
        print("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã! –î–µ–ø–ª–æ–π –∑–∞–ø—Ä–µ—â—ë–Ω.")
        return False

    if improvable_count / total > 0.6:
        print("‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç—Ä–µ–±—É—é—Ç —É–ª—É—á—à–µ–Ω–∏—è (>60%). –î–µ–ø–ª–æ–π –∑–∞–ø—Ä–µ—â—ë–Ω.")
        return False

    print("‚úÖ –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –ø–æ—Ä—è–¥–∫–µ. –î–µ–ø–ª–æ–π —Ä–∞–∑—Ä–µ—à—ë–Ω.")
    return True


def main():
    parser = argparse.ArgumentParser(description='SQL –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —á–µ—Ä–µ–∑ OpenRouter')
    parser.add_argument('--results', default='explain_results.json', help='–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —Å EXPLAIN ANALYZE')
    parser.add_argument('--report', default='llm_report.json', help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –æ—Ç—á—ë—Ç–∞')
    args = parser.parse_args()

    try:
        analyzer = OpenRouterAnalyzer()
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä: {e}")
        sys.exit(1)

    report = generate_report(args.results, analyzer)

    try:
        with open(args.report, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        logger.info(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {args.report}")
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç: {e}")
        sys.exit(1)

    if not check_deployment_criteria(report):
        sys.exit(1)

    sys.exit(0)


if __name__ == '__main__':
    main()