#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä SQL-–∑–∞–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ DeepSeek.
–†–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û —Å DeepSeek API.
"""

import json
import argparse
import os
import sys
import logging
from typing import Dict, List, Any

# –ò—Å–ø–æ–ª—å–∑—É–µ–º openai-–∫–ª–∏–µ–Ω—Ç (DeepSeek —Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenAI API)
import openai


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
logger = logging.getLogger(__name__)


class DeepSeekAnalyzer:
    def __init__(self, api_key: str = None):
        # self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")

        if not self.api_key:
            logger.error("‚ùå –ù–µ –∑–∞–¥–∞–Ω KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
            raise ValueError("API –∫–ª—é—á  –Ω–µ –Ω–∞–π–¥–µ–Ω")

        self.client = openai.OpenAI(
            api_key="free",
            base_url="https://openrouter.ai/api/v1"
        )
        self.model = "google/gemini-flash-1.5-8b"  # –ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –º–æ–¥–µ–ª—å

    def _build_prompt(self, query_data: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è DeepSeek"""
        explain_output = ' '.join(query_data.get('explain_output', [])) if query_data.get('explain_output') else 'N/A'
        tables = ', '.join(query_data.get('tables', [])) if query_data.get('tables') else 'N/A'

        return f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π SQL-–∑–∞–ø—Ä–æ—Å –∏ –µ–≥–æ EXPLAIN ANALYZE –≤—ã–≤–æ–¥ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:
1. –ò–¥–µ–∞–ª—å–Ω—ã–π (GOOD): 
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è < 50ms
   - –ù–µ—Ç seq_scan –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
   - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏

2. –ü—Ä–∏–µ–º–ª–µ–º—ã–π (ACCEPTABLE):
   - –†–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –µ—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
   - Seq scan –Ω–∞ —Ç–∞–±–ª–∏—Ü–∞—Ö < 10k —Å—Ç—Ä–æ–∫
   - –í–æ–∑–º–æ–∂–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Ä–æ—Å—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è < 200ms

3. –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è (NEEDS_IMPROVEMENT):
   - Seq scan –Ω–∞ –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
   - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è JOIN/WHERE
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è > 500ms
   - –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU

4. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π (CRITICAL):
   - DROP/DELETE –±–µ–∑ WHERE
   - –ü–æ–ª–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü > 1M —Å—Ç—Ä–æ–∫
   - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è > 2s
   - –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π

–ó–∞–ø—Ä–æ—Å: 
{query_data['query']}

EXPLAIN ANALYZE –≤—ã–≤–æ–¥:
{explain_output}

–¢–∞–±–ª–∏—Ü—ã: {tables}
–¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_data['type']}

–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Å—Ç—Ä–æ–≥–æ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "evaluation": "GOOD|ACCEPTABLE|NEEDS_IMPROVEMENT|CRITICAL",
  "severity": "LOW|MEDIUM|HIGH|CRITICAL",
  "execution_time": "–≤—Ä–µ–º—è_–≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
  "issues": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"],
  "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2"]
}}
"""

    def analyze_query(self, query_data: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ DeepSeek –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏–∑"""
        prompt = self._build_prompt(query_data)

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=500
            )
            content = response.choices[0].message.content.strip()
            return json.loads(content)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ DeepSeek: {e}")
            return {
                "evaluation": "–æ—à–∏–±–∫–∞_–∞–Ω–∞–ª–∏–∑–∞",
                "severity": "HIGH",
                "issues": [f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {str(e)}"],
                "recommendations": ["–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å SQL –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API"]
            }


def generate_report(results_file: str, analyzer: DeepSeekAnalyzer) -> List[Dict]:
    """–ß–∏—Ç–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã EXPLAIN –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç"""
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {results_file}: {e}")
        sys.exit(1)

    report = []
    for item in results:
        if item.get('error'):
            analysis = {
                "evaluation": "CRITICAL",
                "severity": "CRITICAL",
                "issues": [f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {item['error']}"],
                "recommendations": ["–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å SQL"]
            }
        else:
            analysis = analyzer.analyze_query(item)

        report.append({
            "query": item["query"],
            "type": item["type"],
            "tables": item.get("tables", []),
            "file_path": item.get("file_path", "unknown"),
            "analysis": analysis
        })

    return report


def check_deployment_criteria(report: List[Dict]) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ —Ä–∞–∑—Ä–µ—à–∏—Ç—å –¥–µ–ø–ª–æ–π"""
    critical_count = 0
    improvable_count = 0
    total = len(report)

    if total == 0:
        print("‚ö†Ô∏è –ù–µ—Ç SQL-–∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
        return False

    for item in report:
        eval = item["analysis"]["evaluation"]
        if eval == "CRITICAL":
            critical_count += 1
        if eval in ["NEEDS_IMPROVEMENT", "CRITICAL"]:
            improvable_count += 1

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
    print(f"- –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total}")
    print(f"- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö: {critical_count}")
    print(f"- –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è: {improvable_count}/{total} ({improvable_count / total:.0%})")

    if critical_count > 0:
        print("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã! –î–µ–ø–ª–æ–π –∑–∞–ø—Ä–µ—â—ë–Ω.")
        return False

    if improvable_count / total > 0.6:
        print("‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç—Ä–µ–±—É—é—Ç —É–ª—É—á—à–µ–Ω–∏—è (>60%). –î–µ–ø–ª–æ–π –∑–∞–ø—Ä–µ—â—ë–Ω.")
        return False

    print("‚úÖ –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –ø–æ—Ä—è–¥–∫–µ. –î–µ–ø–ª–æ–π —Ä–∞–∑—Ä–µ—à—ë–Ω.")
    return True


def main():
    parser = argparse.ArgumentParser(description='SQL –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —á–µ—Ä–µ–∑ DeepSeek')
    parser.add_argument('--results', default='explain_results.json', help='–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —Å EXPLAIN ANALYZE')
    parser.add_argument('--report', default='llm_report.json', help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –æ—Ç—á—ë—Ç–∞')
    args = parser.parse_args()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    try:
        analyzer = DeepSeekAnalyzer()
    except ValueError as e:
        logger.error(e)
        sys.exit(1)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
    report = generate_report(args.results, analyzer)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞
    try:
        with open(args.report, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        logger.info(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {args.report}")
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç: {e}")
        sys.exit(1)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª –¥–µ–ø–ª–æ—è
    if not check_deployment_criteria(report):
        sys.exit(1)

    sys.exit(0)


if __name__ == '__main__':
    main()